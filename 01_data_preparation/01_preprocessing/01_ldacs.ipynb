{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Import of required libraries\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from traffic.core import Traffic\n",
    "from traffic.data import airports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Procecessing of SAMAX data\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to folder containing the daily SAMAX files\n",
    "samax_data_path = \"/store/MIAR/01_sources/SAMAX/01_raw\"\n",
    "\n",
    "# Definition of columns to keep\n",
    "cols2keep = {\n",
    "    \"Time [ms since 1.1.1970]\": \"timestamp\",\n",
    "    \"WGS84 lat Float '[-]dd.dddddd' [deg]\": \"latitude\",\n",
    "    \"WGS84 lon Float '[-]ddd.ddddd' [deg]\": \"longitude\",\n",
    "    \"I081/090 Mode C - Float [ft]\": \"altitude\",\n",
    "    \"NC-139 BDS50 Register GS - Int [kt]\": \"groundspeed\",\n",
    "    \"NC-131 Aircraft ID (Downlinked Callsign) - String\": \"callsign\",\n",
    "    # Kept for reducing to Takeoffs on 28\n",
    "    \"NC-046 Target Direction - Int [ |1..6] (1=ARR/2=DEP/3=LOC/4=TRANS/5=MOV/6=UNK)\": \"direction\",\n",
    "    \"NC-052 Allocated RWY - String\": \"RWY\",\n",
    "}\n",
    "\n",
    "# List of daily csv files in the SAMAX folder\n",
    "all_csv_files = glob.glob(f\"{samax_data_path}/**/*.csv\", recursive=True)\n",
    "\n",
    "# List to store the read data\n",
    "df_samax = []\n",
    "\n",
    "# Read all csv files to a pandas dataframe, keeping only the columns defined in\n",
    "# cols2keep and filtering for takeoffs on runway 28. Direction and RWY columns\n",
    "# are removed.\n",
    "for f in tqdm(all_csv_files):\n",
    "    try:\n",
    "        df_samax.append(\n",
    "            pd.read_csv(\n",
    "                f,\n",
    "                sep=\";\",\n",
    "                usecols=cols2keep.keys(),\n",
    "                parse_dates=True,\n",
    "            )\n",
    "            .rename(columns=cols2keep)\n",
    "            .query(\n",
    "                \"(direction == '1' and RWY == '14') | (direction == '2' and RWY == '28')\"\n",
    "            )\n",
    "            .drop(columns=[\"direction\", \"RWY\"])\n",
    "        )\n",
    "    # Skip files that raise an error\n",
    "    except Exception as e:\n",
    "        print(f\"Error with file {f}: {e}\")\n",
    "        pass\n",
    "\n",
    "# Concatenate all daily dataframes\n",
    "print(\"concatenating\")\n",
    "df_samax = pd.concat(df_samax, ignore_index=True)\n",
    "\n",
    "# # change type of some columns:\n",
    "df_samax[\"timestamp\"] = pd.to_datetime(\n",
    "    df_samax[\"timestamp\"], unit=\"ms\", utc=True\n",
    ")\n",
    "\n",
    "# Convert to traffic, resample,  and reduce to 20nm radius around airport\n",
    "t = Traffic(df_samax)\n",
    "t = (\n",
    "    t.assign_id()\n",
    "    .resample(\"1s\")\n",
    "    .distance(airports[\"LSZH\"])\n",
    "    .query(\"distance < 20\")\n",
    "    .eval(max_workers=30, desc=\"Resampling and reduction to 20nm\")\n",
    ")\n",
    "t.data.drop(\n",
    "    columns=\"distance\",\n",
    "    axis=1,\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "\n",
    "# Remove part before the start of the take-off roll\n",
    "def after_to_roll(flight):\n",
    "    try:\n",
    "        t0 = flight.data.query(\n",
    "            \"8.56695<longitude<8.5695 and 47.45659<latitude<47.457\"\n",
    "        ).timestamp.min()\n",
    "        return flight.after(t0)\n",
    "    except:\n",
    "        return\n",
    "\n",
    "\n",
    "t = (\n",
    "    t.iterate_lazy()\n",
    "    .pipe(after_to_roll)\n",
    "    .eval(desc=\"processing\", max_workers=30)\n",
    ")\n",
    "\n",
    "# Save traffic as parquet\n",
    "t.to_parquet(\"/mnt/beegfs/store/krum/MT/inputs/samax_trajs.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Processing of FZAG mass data\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import and processing of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Loading the FZAG mass data\n",
    "fzag_data_path = \"/mnt/beegfs/store/MIAR/01_sources/FZAG\"\n",
    "df_departures = (\n",
    "    pd.read_csv(\n",
    "        f\"{fzag_data_path}/df_departure.csv\", sep=\",\", header=0, index_col=0\n",
    "    )\n",
    "    .rename(\n",
    "        columns={\n",
    "            \"SDT\": \"date\",\n",
    "            \"CSG\": \"callsign\",\n",
    "            \"TWT\": \"toff_weight_kg\",\n",
    "            \"ITY\": \"typecode\",\n",
    "        }\n",
    "    )\n",
    "    .drop(columns=[\"REG\"])\n",
    ")\n",
    "\n",
    "# Turning the date column into a datetime object\n",
    "df_departures[\"date\"] = pd.to_datetime(df_departures[\"date\"])\n",
    "\n",
    "# Dropping rows with NaN values in the toff_weight_kg column\n",
    "df_departures = df_departures[df_departures[\"toff_weight_kg\"].notna()]\n",
    "\n",
    "# Add column with airline ICAO code\n",
    "df_departures[\"ICAO\"] = df_departures[\"callsign\"].str.slice(0, 3)\n",
    "\n",
    "# Removal of Swiss Air Force and invalid ICAO codes\n",
    "df_departures = df_departures[\n",
    "    df_departures[\"ICAO\"].isin([\"SWR\", \"EDW\", \"DLH\", \"ADR\", \"BEL\"])\n",
    "]\n",
    "\n",
    "# Removal of rare typecodes\n",
    "df_departures = df_departures[\n",
    "    ~df_departures[\"typecode\"].isin([\"CRJ7\", \"CRJX\", \"B734\"])\n",
    "]\n",
    "\n",
    "# Save the processed FZAG data\n",
    "df_departures.to_parquet(f\"/mnt/beegfs/store/krum/MT/inputs/df_mass.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Poetry via SLURM MIAR",
   "language": "python",
   "name": "jupyter-eg-kernel-slurm-py39-poetry-1ho6psb1p"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
