{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Import of required libraries\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from traffic.core import Traffic\n",
    "import numpy as np\n",
    "from multiprocessing import Pool\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Import of data\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_train = Traffic.from_file(\n",
    "    \"/mnt/beegfs/store/krum/MT/encoded_scaled_split/t_train.parquet\"\n",
    ")\n",
    "t_val = Traffic.from_file(\n",
    "    \"/mnt/beegfs/store/krum/MT/encoded_scaled_split/t_val.parquet\"\n",
    ")\n",
    "t_test = Traffic.from_file(\n",
    "    \"/mnt/beegfs/store/krum/MT/encoded_scaled_split/t_test.parquet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Sample generation\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate samples for one flight\n",
    "def process_flight(\n",
    "    flight: Traffic,\n",
    "    n_rows_input: int,\n",
    "    n_rows_output: int,\n",
    "    input_columns: list,\n",
    "    out_columns: list,\n",
    "    overlap: int,\n",
    "    interval: int,\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate samples for one flight\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    flight : Traffic.core.flight.Flight\n",
    "        Flight to generate samples from\n",
    "    n_rows_input : int\n",
    "        Number of rows to include in the input (length of the input sequence)\n",
    "    n_rows_output : int\n",
    "        Number of rows to include in the output (length of the output sequence)\n",
    "    input_columns : list\n",
    "        List of columns to include in the input\n",
    "    out_columns : list\n",
    "        List of columns to include in the output\n",
    "    overlap : int\n",
    "        Number of timesteps to overlap between input and output\n",
    "    interval : int\n",
    "        Interval between output samples\n",
    "    \"\"\"\n",
    "    # List to store the input and output samples\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    # Extract the data for the flight\n",
    "    flight_data = flight.data[input_columns]\n",
    "    # Iterate over each possible starting point for the input sequence\n",
    "    for i in range(0, len(flight.data) - n_rows_input - n_rows_output + 1):\n",
    "        # Extract the input and output data\n",
    "        input_data = flight_data.iloc[i : (i + n_rows_input)]\n",
    "        output_data = flight_data.iloc[\n",
    "            (i + n_rows_input - overlap) : (i + n_rows_input + n_rows_output) : interval\n",
    "        ]\n",
    "        # Append the input and output samples\n",
    "        inputs.append(input_data.values)\n",
    "        outputs.append(output_data[out_columns].values)\n",
    "    # Return the input and output samples\n",
    "    return np.array(inputs), np.array(outputs)\n",
    "\n",
    "\n",
    "# Columns to include in the input\n",
    "input_columns = [\n",
    "    \"latitude_scaled\",\n",
    "    \"longitude_scaled\",\n",
    "    \"altitude_scaled\",\n",
    "    \"wind_x_2min_avg_scaled\",\n",
    "    \"wind_y_2min_avg_scaled\",\n",
    "    \"temperature_gnd_scaled\",\n",
    "    \"humidity_gnd_scaled\",\n",
    "    \"pressure_gnd_scaled\",\n",
    "    \"toff_weight_kg_scaled\",\n",
    "    \"typecode_A20N\",\n",
    "    \"typecode_A21N\",\n",
    "    \"typecode_A319\",\n",
    "    \"typecode_A320\",\n",
    "    \"typecode_A321\",\n",
    "    \"typecode_A333\",\n",
    "    \"typecode_A343\",\n",
    "    \"typecode_B77W\",\n",
    "    \"typecode_BCS1\",\n",
    "    \"typecode_BCS3\",\n",
    "    \"typecode_CRJ9\",\n",
    "    \"typecode_DH8D\",\n",
    "    \"typecode_E190\",\n",
    "    \"typecode_E195\",\n",
    "    \"typecode_E290\",\n",
    "    \"typecode_E295\",\n",
    "    \"typecode_F100\",\n",
    "    \"typecode_SB20\",\n",
    "    \"SID_DEGES\",\n",
    "    \"SID_GERSA\",\n",
    "    \"SID_VEBIT\",\n",
    "    \"SID_ZUE\",\n",
    "    \"hour_sin\",\n",
    "    \"hour_cos\",\n",
    "    \"weekday_sin\",\n",
    "    \"weekday_cos\",\n",
    "    \"month_sin\",\n",
    "    \"month_cos\",\n",
    "]\n",
    "\n",
    "# Columns to include in the output\n",
    "output_columns = [\"latitude_scaled\", \"longitude_scaled\", \"altitude_scaled\"]\n",
    "\n",
    "# Parameters for the generation of samples\n",
    "t_in = 10\n",
    "t_out = 180\n",
    "interval_out = 5\n",
    "overlap = 1\n",
    "\n",
    "# Generate samples for the training, validation and test sets\n",
    "for traffic_data, set_name in zip([t_train, t_val, t_test], [\"train\", \"val\", \"test\"]):\n",
    "    # Parallelisation of the generation of samples\n",
    "    chunks = [\n",
    "        (\n",
    "            flight,\n",
    "            t_in,\n",
    "            t_out,\n",
    "            input_columns,\n",
    "            output_columns,\n",
    "            overlap,\n",
    "            interval_out,\n",
    "        )\n",
    "        for flight in traffic_data\n",
    "    ]\n",
    "    with Pool(20) as p:\n",
    "        results = p.starmap(process_flight, tqdm(chunks))\n",
    "\n",
    "    # Concatenate the results\n",
    "    inputs_list = [result[0] for result in results if result[0].size > 0]\n",
    "    outputs_list = [result[1] for result in results if result[1].size > 0]\n",
    "    inputs = np.concatenate(inputs_list, axis=0)\n",
    "    outputs = np.concatenate(outputs_list, axis=0)\n",
    "\n",
    "    # Save the samples\n",
    "    np.save(\n",
    "        f\"/mnt/beegfs/store/krum/MT/samples/{set_name}_in32.npy\",\n",
    "        inputs.astype(np.float32),\n",
    "    )\n",
    "    np.save(\n",
    "        f\"/mnt/beegfs/store/krum/MT/samples/{set_name}_out32.npy\",\n",
    "        outputs.astype(np.float32),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Splitting into variable and constant features\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each set (train, val, test)\n",
    "for set in [\"train\", \"val\", \"test\"]:\n",
    "    # Load the input samples\n",
    "    arra_in = np.load(f\"/mnt/beegfs/store/krum/MT/samples/{set}_in32.npy\")\n",
    "    # Split the input samples into variable and constant inputs\n",
    "    in_var = train_in_tvar = arra_in[:, :, :8]\n",
    "    in_con = train_in_tcon = arra_in[:, 0:1, 8:]\n",
    "    # Save the separated input samples\n",
    "    np.save(\n",
    "        f\"/mnt/beegfs/store/krum/MT/samples/{set}_in32_var.npy\",\n",
    "        in_var.astype(np.float32),\n",
    "    )\n",
    "    np.save(\n",
    "        f\"/mnt/beegfs/store/krum/MT/samples/{set}_in32_con.npy\",\n",
    "        in_con.astype(np.float32),\n",
    "    )\n",
    "    # Print the shape of the input samples\n",
    "    print(f\"Variable input shape {set}: {in_var.shape}\")\n",
    "    print(f\"Constant input shape {set}: {in_con.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Poetry via SLURM MIAR",
   "language": "python",
   "name": "jupyter-eg-kernel-slurm-py39-poetry-1ho6psb1p"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
