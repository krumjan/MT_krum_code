{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Import of required libraries\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from geopy.distance import distance\n",
    "\n",
    "from traffic.core import Traffic\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Import of data, model and scalers\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Trajectory data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Traffic.from_file(\n",
    "    \"/mnt/beegfs/store/krum/MT/encoded_scaled_split/t_test.parquet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse_lat():\n",
    "    return None\n",
    "\n",
    "\n",
    "def rmse_lon():\n",
    "    return None\n",
    "\n",
    "\n",
    "def rmse_alt():\n",
    "    return None\n",
    "\n",
    "\n",
    "model = load_model(\n",
    "    f\"/home/krum/git/MT_krum_code/models/snowy-gorge-126.keras\",\n",
    "    custom_objects={\n",
    "        \"rmse_lat\": rmse_lat,\n",
    "        \"rmse_lon\": rmse_lon,\n",
    "        \"rmse_alt\": rmse_alt,\n",
    "        \"weighted_mse\": tf.keras.losses.MeanSquaredError(),\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Scalers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler_in\n",
    "with open(\n",
    "    \"/mnt/beegfs/store/krum/MT/encoded_scaled_split/scaler_in.pkl\",\n",
    "    \"rb\",\n",
    ") as file:\n",
    "    scaler_in = pickle.load(file)\n",
    "\n",
    "# scaler_out\n",
    "with open(\n",
    "    \"/mnt/beegfs/store/krum/MT/encoded_scaled_split/scaler_out.pkl\",\n",
    "    \"rb\",\n",
    ") as file:\n",
    "    scaler_out = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Model application\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_var_unscaled = []\n",
    "inputs_var = []\n",
    "inputs_con = []\n",
    "\n",
    "for flight in tqdm(t):\n",
    "    f_in_var_unscaled = flight.data[\n",
    "        [\n",
    "            \"latitude\",\n",
    "            \"longitude\",\n",
    "            \"altitude\",\n",
    "        ]\n",
    "    ].iloc[-11:-1]\n",
    "    inputs_var_unscaled.append(f_in_var_unscaled)\n",
    "\n",
    "    input_var = (\n",
    "        flight.data[\n",
    "            [\n",
    "                \"latitude_scaled\",\n",
    "                \"longitude_scaled\",\n",
    "                \"altitude_scaled\",\n",
    "                \"wind_x_2min_avg_scaled\",\n",
    "                \"wind_y_2min_avg_scaled\",\n",
    "                \"temperature_gnd_scaled\",\n",
    "                \"humidity_gnd_scaled\",\n",
    "                \"pressure_gnd_scaled\",\n",
    "            ]\n",
    "        ]\n",
    "        .iloc[-11:-1]\n",
    "        .to_numpy()\n",
    "        .reshape(10, 8)\n",
    "    )\n",
    "    inputs_var.append(input_var)\n",
    "\n",
    "    input_con = (\n",
    "        flight.data[\n",
    "            [\n",
    "                \"toff_weight_kg_scaled\",\n",
    "                \"typecode_A20N\",\n",
    "                \"typecode_A21N\",\n",
    "                \"typecode_A319\",\n",
    "                \"typecode_A320\",\n",
    "                \"typecode_A321\",\n",
    "                \"typecode_A333\",\n",
    "                \"typecode_A343\",\n",
    "                \"typecode_B77W\",\n",
    "                \"typecode_BCS1\",\n",
    "                \"typecode_BCS3\",\n",
    "                \"typecode_CRJ9\",\n",
    "                \"typecode_DH8D\",\n",
    "                \"typecode_E190\",\n",
    "                \"typecode_E195\",\n",
    "                \"typecode_E290\",\n",
    "                \"typecode_E295\",\n",
    "                \"typecode_F100\",\n",
    "                \"typecode_SB20\",\n",
    "                \"SID_DEGES\",\n",
    "                \"SID_GERSA\",\n",
    "                \"SID_VEBIT\",\n",
    "                \"SID_ZUE\",\n",
    "                \"hour_sin\",\n",
    "                \"hour_cos\",\n",
    "                \"weekday_sin\",\n",
    "                \"weekday_cos\",\n",
    "                \"month_sin\",\n",
    "                \"month_cos\",\n",
    "            ]\n",
    "        ]\n",
    "        .iloc[-11]\n",
    "        .to_numpy()\n",
    "        .reshape(1, 29)\n",
    "    )\n",
    "    inputs_con.append(input_con)\n",
    "\n",
    "# Convert to numpy arrays\n",
    "inputs_var = np.vstack(inputs_var).reshape(len(t), 10, 8)\n",
    "inputs_con = np.vstack(inputs_con).reshape(len(t), 1, 29)\n",
    "\n",
    "# Predict\n",
    "predictions = model.predict((inputs_var, inputs_con))\n",
    "\n",
    "# Unscale\n",
    "predictions_unscaled = scaler_out.inverse_transform(\n",
    "    predictions.reshape(-1, 3)\n",
    ").reshape(37061, 37, 3)[1:, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Plotting\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample selection\n",
    "sample = 8\n",
    "\n",
    "# Generate subplots------------------------------------------------------------\n",
    "fig = make_subplots(\n",
    "    rows=2,\n",
    "    cols=1,\n",
    "    specs=[[{\"type\": \"scattermapbox\"}], [{}]],\n",
    "    row_heights=[0.6, 0.4],\n",
    "    subplot_titles=(\"Position\", \"Altitude\"),\n",
    "    vertical_spacing=0.07,\n",
    ")\n",
    "\n",
    "# Add traces-------------------------------------------------------------------\n",
    "# Input position\n",
    "fig.append_trace(\n",
    "    go.Scattermapbox(\n",
    "        lat=inputs_var_unscaled[sample][\"latitude\"],\n",
    "        lon=inputs_var_unscaled[sample][\"longitude\"],\n",
    "        marker=dict(size=5, color=\"red\"),\n",
    "        mode=\"markers\",\n",
    "        showlegend=False,\n",
    "    ),\n",
    "    row=1,\n",
    "    col=1,\n",
    ")\n",
    "\n",
    "# Prediction position\n",
    "fig.append_trace(\n",
    "    go.Scattermapbox(\n",
    "        lat=predictions_unscaled[sample, :, 0],\n",
    "        lon=predictions_unscaled[sample, :, 1],\n",
    "        marker=dict(size=5, color=\"blue\"),\n",
    "        mode=\"markers\",\n",
    "        showlegend=False,\n",
    "    ),\n",
    "    row=1,\n",
    "    col=1,\n",
    ")\n",
    "\n",
    "# Input altitude\n",
    "fig.append_trace(\n",
    "    go.Scatter(\n",
    "        x=np.arange(0, len(inputs_var_unscaled[0])),\n",
    "        y=inputs_var_unscaled[0][\"altitude\"],\n",
    "        marker=dict(size=3, color=\"red\"),\n",
    "        mode=\"markers\",\n",
    "        name=\"full\",\n",
    "        showlegend=False,\n",
    "    ),\n",
    "    row=2,\n",
    "    col=1,\n",
    ")\n",
    "\n",
    "# Prediction altitude\n",
    "fig.append_trace(\n",
    "    go.Scatter(\n",
    "        x=np.arange(10, 5*(10+len(predictions_unscaled[sample, :, 2])), 5),\n",
    "        y=predictions_unscaled[sample, :, 2],\n",
    "        marker=dict(size=3, color=\"blue\"),\n",
    "        mode=\"markers\",\n",
    "        name=\"full\",\n",
    "        showlegend=False,\n",
    "    ),\n",
    "    row=2,\n",
    "    col=1,\n",
    ")\n",
    "\n",
    "# Update Figure layout---------------------------------------------------------\n",
    "fig.update_layout(\n",
    "    mapbox=dict(\n",
    "        style=\"carto-positron\",\n",
    "        zoom=10,\n",
    "        # center=dict(\n",
    "        #     lat=np.mean(df_full[\"latitude\"].mean()),\n",
    "        #     lon=np.mean(df_full[\"longitude\"].mean()),\n",
    "        # ),\n",
    "    ),\n",
    "    width=1200,\n",
    "    height=1200,\n",
    "    margin=dict(l=50, r=0, t=40, b=40),\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Poetry via SLURM MIAR",
   "language": "python",
   "name": "jupyter-eg-kernel-slurm-py39-poetry-1ho6psb1p"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
